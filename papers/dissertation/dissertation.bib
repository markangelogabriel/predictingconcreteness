@inproceedings{charbonnier-wartena-2019-predicting,
    title = "Predicting Word Concreteness and Imagery",
    author = "Charbonnier, Jean  and
      Wartena, Christian",
    booktitle = "Proceedings of the 13th International Conference on Computational Semantics - Long Papers",
    month = may,
    year = "2019",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-0415",
    doi = "10.18653/v1/W19-0415",
    pages = "176--187",
    abstract = "Concreteness of words has been studied extensively in psycholinguistic literature. A number of datasets have been created with average values for perceived concreteness of words. We show that we can train a regression model on these data, using word embeddings and morphological features, that can predict these concreteness values with high accuracy. We evaluate the model on 7 publicly available datasets. Only for a few small subsets of these datasets prediction of concreteness values are found in the literature. Our results clearly outperform the reported results for these datasets.",
}

@inproceedings{ctree,
    title = "ctree: Conditional Inference Trees",
     author={T. Hothorn and K. Hornik and A. Zeileis},
    year = "2015",
    abstract = "This vignette describes the new reimplementation of conditional inference trees (CTree) in the R package partykit. CTree is a non-parametric class of regression trees embedding tree-structured regression models into a well defined theory of conditional inference procedures. It is applicable to all kinds of regression problems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. The vignette comprises a practical guide to exploiting the flexible and extensible computational tools in partykit for fitting and visualizing conditional inference trees."
}

@inproceedings{ruder2019transfer,
	title={Transfer Learning in Natural Language Processing},
	author={Ruder, Sebastian and Peters, Matthew E and Swayamdipta, Swabha and Wolf, Thomas},
	booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials},
	pages={15--18},
	year={2019}
}

@INPROCEEDINGS{alshahrani2019xlnet,
	author={A. {Alshahrani} and M. {Ghaffari} and K. {Amirizirtol} and X. {Liu}},
	booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
	title={Identifying Optimism and Pessimism in Twitter Messages Using XLNet and Deep Consensus}, 
	year={2020},
	volume={},
	number={},
	pages={1-8},
	doi={10.1109/IJCNN48605.2020.9206948}}

@article{Mozeti__2016,
	title={Multilingual Twitter Sentiment Classification: The Role of Human Annotators},
	volume={11},
	ISSN={1932-6203},
	url={http://dx.doi.org/10.1371/journal.pone.0155036},
	DOI={10.1371/journal.pone.0155036},
	number={5},
	journal={PLOS ONE},
	publisher={Public Library of Science (PLoS)},
	author={Mozetič, Igor and Grčar, Miha and Smailović, Jasmina},
	editor={Perc, MatjazEditor},
	year={2016},
	month={May},
	pages={e0155036}
}


@misc{dai2019transformerxl,
	title={Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context}, 
	author={Zihang Dai and Zhilin Yang and Yiming Yang and Jaime Carbonell and Quoc V. Le and Ruslan Salakhutdinov},
	year={2019},
	eprint={1901.02860},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{vaswani2017attention,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@misc{yang2020xlnet,
	title={XLNet: Generalized Autoregressive Pretraining for Language Understanding}, 
	author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
	year={2020},
	eprint={1906.08237},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{Wolf2019HuggingFacesTS,
	title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
	author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
	journal={ArXiv},
	year={2019},
	volume={abs/1910.03771}
}

@inproceedings{stewart-etal-2019-redcoat,
	title = "{R}edcoat: A Collaborative Annotation Tool for Hierarchical Entity Typing",
	author = "Stewart, Michael  and
	Liu, Wei  and
	Cardell-Oliver, Rachel",
	booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations",
	month = nov,
	year = "2019",
	address = "Hong Kong, China",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D19-3033",
	doi = "10.18653/v1/D19-3033",
	pages = "193--198",
	abstract = "We introduce Redcoat, a web-based annotation tool that supports collaborative hierarchical entity typing. As an annotation tool, Redcoat also facilitates knowledge elicitation by allowing the creation and continuous refinement of concept hierarchies during annotation. It aims to minimise not only annotation time but the time it takes for project creators to set up and distribute projects to annotators. Projects created using the web-based interface can be rapidly distributed to a list of email addresses. Redcoat handles the propagation of documents amongst annotators and automatically scales the annotation workload depending on the number of active annotators. In this paper we discuss these key features and outline Redcoat{'}s system architecture. We also highlight Redcoat{'}s unique benefits over existing annotation tools via a qualitative comparison.",
}

@Article{Kosslyn2001,
	author={Kosslyn, Stephen M.
	and Ganis, Giorgio
	and Thompson, William L.},
	title={Neural foundations of imagery},
	journal={Nature Reviews Neuroscience},
	year={2001},
	month={Sep},
	day={01},
	volume={2},
	number={9},
	pages={635-642},
	abstract={Recent advances in cognitive neuroscience, including functional brain-imaging techniques, have shown that mental imagery makes use of much the same neural substrates as perception in the same sensory modality. Visual mental imagery seems to use the same two pathways (ventral or object processing, and dorsal or spatial processing) as perception. Defects in one or other pathway often, but not always, produce parallel deficits in both perception and imagery. Auditory and motor imagery also draw on cortical areas involved in auditory perception and motor control, respectively. There is evidence that early visual cortex (areas 17 and 18) is activated during some types of mental imagery. Detection of such activity seems to rely on the use of the most sensitive imaging techniques. It is possible that these areas are activated only if the imagery task used requires subjects to find high-resolution detail in a mental image. Imagery of emotional events can activate the autonomic nervous system and amygdala in a similar way to perception of the same events, leading to physiological changes. For example, imagining threatening events can increase heart rate, skin conductance and breathing rate. Future research should clarify the involvement of primary sensory cortices in imagery, and investigate individual variation in imagery abilities, among other issues. New imaging techniques, such as functional diffuse optical tomography, will aid these advances.},
	issn={1471-0048},
	doi={10.1038/35090055},
	url={https://doi.org/10.1038/35090055}
}

@Article{Pearson2013,
	author={Pearson, David G.
	and Deeprose, Catherine
	and Wallace-Hadrill, Sophie M. A.
	and Burnett Heyes, Stephanie
	and Holmes, Emily A.},
	title={Assessing mental imagery in clinical psychology: a review of imagery measures and a guiding framework},
	journal={Clinical psychology review},
	year={2013},
	month={Feb},
	edition={2012/09/11},
	publisher={Elsevier Science},
	volume={33},
	number={1},
	pages={1-23},
	keywords={Depression/diagnosis/*psychology; Humans; *Imagination; Phobic Disorders/diagnosis/*psychology; Psychology, Clinical/*methods; Psychometrics; *Schizophrenia/diagnosis; *Schizophrenic Psychology; Stress Disorders, Post-Traumatic/diagnosis/*psychology},
	abstract={Mental imagery is an under-explored field in clinical psychology research but presents a topic of potential interest and relevance across many clinical disorders, including social phobia, schizophrenia, depression, and post-traumatic stress disorder. There is currently a lack of a guiding framework from which clinicians may select the domains or associated measures most likely to be of appropriate use in mental imagery research. We adopt an interdisciplinary approach and present a review of studies across experimental psychology and clinical psychology in order to highlight the key domains and measures most likely to be of relevance. This includes a consideration of methods for experimentally assessing the generation, maintenance, inspection and transformation of mental images; as well as subjective measures of characteristics such as image vividness and clarity. We present a guiding framework in which we propose that cognitive, subjective and clinical aspects of imagery should be explored in future research. The guiding framework aims to assist researchers in the selection of measures for assessing those aspects of mental imagery that are of most relevance to clinical psychology. We propose that a greater understanding of the role of mental imagery in clinical disorders will help drive forward advances in both theory and treatment.},
	note={23123567[pmid]},
	note={PMC3545187[pmcid]},
	note={S0272-7358(12)00136-5[PII]},
	issn={1873-7811},
	doi={10.1016/j.cpr.2012.09.001},
	url={https://pubmed.ncbi.nlm.nih.gov/23123567},
	url={https://doi.org/10.1016/j.cpr.2012.09.001},
	language={eng}
}

@Article{Patel2005,
	author={T. Patel and C.R. Brewin and J. Wheatley and A. Wells and P. Fisher and S. Myers},
	title={Intrusive images and memories in major depression},
	journal={Behavior Research and Therapy},
	year={2007},
	month={Nov},
	edition={2007/06/16},
	publisher={Elsevier Science},
	volume={45},
	number={11},
	pages={2573–2580},
	keywords={Depression; Memory; Imagery; Dissociation},
	abstract={Individuals with current major depression were interviewed to investigate the prevalence of distressing intrusive mental imagery among depressed patients and study the phenomenology of these intrusions. Of the 39 currently depressed patients, 17 experienced some form of repetitive intrusive imagery (i.e., either an intrusive memory or image), with intrusive memories being more common than images. The intrusive imagery was experienced as highly uncontrollable and interfered significantly with patients' everyday lives. The intrusions were experienced with a sense of 'nowness', as well as physical and emotional re-experiencing. Despite high levels of re-experiencing, levels of dissociation were very low. The intrusive imagery was in some patients part of a wider network of key defining autobiographical memories, consistent with the idea that it is likely to play a significant role in maintaining the patient's depressive mood. Interventions targeting these intrusions could potentially result in a positive shift in depressed mood.},
	issn={1873-7811},
	doi={/10.1016/j.brat.2007.06.004},
	url={https://doi.org/10.1016/j.brat.2007.06.004},
	language={eng}
}

@article{motivationalamplifier,
	title = "Mental imagery as a “motivational amplifier” to promote activities",
	abstract = "Facilitating engagement in rewarding activities is a key treatment target in depression. Mental imagery can increase engagement in planned behaviours, potentially due to its special role in representing emotionally salient experiences. The present study tested the hypothesis that mental imagery promotes motivation and engagement when planning pleasant and rewarding activities. Participants were recruited from a community volunteer panel (N = 72). They self-nominated six activities to complete over the following week, and were randomized to either: a) a single-session Motivational Imagery condition (N = 24); b) an Activity Reminder control condition (N = 24); or c) a No-Reminder control condition (N = 24). As predicted, relative to control groups, the Motivational Imagery group reported higher levels of motivation, anticipated pleasure, and anticipated reward for the planned activities. The Motivational Imagery group also completed significantly more activities than the Activity Reminder group, but not more than the No-Reminder group. Relevance of results to behavioural activation approaches for depression are discussed.",
	keywords = "Activity scheduling, Behavioural activation, Mental imagery, Mental simulation",
	author = "Fritz Renner and Murphy, {Fionnuala C.} and Ji, {Julie L.} and Tom Manly and Holmes, {Emily A.}",
	year = "2019",
	month = mar,
	day = "1",
	doi = "10.1016/j.brat.2019.02.002",
	language = "English",
	volume = "114",
	pages = "51--59",
	journal = "Behaviour Research \& Therapy",
	issn = "0005-7967",
	publisher = "Pergamon",
}

@article{conceptualandclinical,
	title = "Mental imagery in psychiatry: Conceptual \& clinical implications",
	abstract = "Mental imagery refers to the experience of perception in the absence of external sensory input. Deficits in the ability to generate mental imagery or to distinguish it from actual sensory perception are linked to neurocognitive conditions such as dementia and schizophrenia, respectively. However, the importance of mental imagery to psychiatry extends beyond neurocognitive impairment. Mental imagery has a stronger link to emotion than verbal-linguistic cognition, serving to maintain and amplify emotional states, with downstream impacts on motivation and behavior. As a result, anomalies in the occurrence of emotion-laden mental imagery has transdiagnostic significance for emotion, motivation, and behavioral dysfunction across mental disorders. This review aims to demonstrate the conceptual and clinical significance of mental imagery in psychiatry through examples of mood and anxiety disorders, self-harm and suicidality, and addiction. We contend that focusing on mental imagery assessment in research and clinical practice can increase our understanding of the cognitive basis of psychopathology in mental disorders, with the potential to drive the development of algorithms to aid treatment decision-making and inform transdiagnostic treatment innovation.",
	keywords = "addiction, anxiety disorders, dementia, emotion, mental imagery, mood disorders, motivation, schizophrenia, self-harm",
	author = "Ji, {Julie L.} and Kavanagh, {David J.} and Holmes, {Emily A.} and Colin Macleod and {Di Simplicio}, Martina",
	year = "2019",
	month = feb,
	doi = "10.1017/S1092852918001487",
	language = "English",
	volume = "24",
	pages = "114--126",
	journal = "CNS Spectrums: the international journal of neuropsychiatric medicine",
	issn = "1092-8529",
	publisher = "Cambridge University Press",
	number = "1",
}

@article{semanticmeasures,
	title = "Semantic measures: Using natural language processing to measure, differentiate, and describe psychological constructs",
	abstract = "Psychological constructs, such as emotions, thoughts, and attitudes are often measured by asking individuals to reply to questions using closed-ended numerical rating scales. However, when asking people about their state of mind in a natural context (“How are you?”), we receive open-ended answers using words (“Fine and happy!”) and not closed-ended answers using numbers (“7”) or categories (“A lot”). Nevertheless, to date it has been difficult to objectively quantify responses to open-ended questions. We develop an approach using open-ended questions in which the responses are analyzed using natural language processing (Latent Semantic Analyses). This approach of using open-ended, semantic questions is compared with traditional rating scales in nine studies (N = 92–854), including two different study paradigms. The first paradigm requires participants to describe psychological aspects of external stimuli (facial expressions) and the second paradigm involves asking participants to report their subjective well-being and mental health problems. The results demonstrate that the approach using semantic questions yields good statistical properties with competitive, or higher, validity and reliability compared with corresponding numerical rating scales. As these semantic measures are based on natural language and measure, differentiate, and describe psychological constructs, they have the potential of complementing and extending traditional rating scales. (APA PsycInfo Database Record (c) 2019 APA, all rights reserved)",
	author = "Kjell, {O. N. E.} and Kjell, K. and Garcia, D. and Sikström, S.",
	year = "2019",
	month = feb,
	doi = "10.1037/met0000191",
	language = "English",
	volume = "24",
	pages = "92-115",
	journal = "Psychological Methods",
	issn = "1082-989X",
	publisher = "American Psychological Association",
	number = "1",
}


@article{bert,
	author    = {Jacob Devlin and
	Ming{-}Wei Chang and
	Kenton Lee and
	Kristina Toutanova},
	title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
	Understanding},
	journal   = {CoRR},
	volume    = {abs/1810.04805},
	year      = {2018},
	url       = {http://arxiv.org/abs/1810.04805},
	archivePrefix = {arXiv},
	eprint    = {1810.04805},
	timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bertsentimentanalysis,
	title={Exploiting BERT for End-to-End Aspect-based Sentiment Analysis},
	url={http://dx.doi.org/10.18653/v1/D19-5505},
	DOI={10.18653/v1/d19-5505},
	journal={Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)},
	publisher={Association for Computational Linguistics},
	author={Li, Xin and Bing, Lidong and Zhang, Wenxuan and Lam, Wai},
	year={2019}
}

@article{nonclinicalnlp,
	author = {Calvo, Rafael and Milne, David and Hussain, Sazzad and Christensen, Helen},
	year = {2017},
	month = {01},
	pages = {1-37},
	title = {Natural language processing in mental health applications using non-clinical texts},
	journal = {Natural Language Engineering},
	doi = {10.1017/S1351324916000383}
}

@article{roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bilstm,
  author    = {Zhiheng Huang and
               Wei Xu and
               Kai Yu},
  title     = {Bidirectional {LSTM-CRF} Models for Sequence Tagging},
  journal   = {CoRR},
  volume    = {abs/1508.01991},
  year      = {2015},
  url       = {http://arxiv.org/abs/1508.01991},
  archivePrefix = {arXiv},
  eprint    = {1508.01991},
  timestamp = {Tue, 15 Sep 2020 18:57:32 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HuangXY15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
