{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main resource: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "flair.device = device\n",
    "\n",
    "print(flair.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 18:02:42,784 Reading data from ..\\data\\corpuslow_13042021\n",
      "2021-04-18 18:02:42,784 Train: ..\\data\\corpuslow_13042021\\train.csv\n",
      "2021-04-18 18:02:42,785 Dev: ..\\data\\corpuslow_13042021\\dev.csv\n",
      "2021-04-18 18:02:42,786 Test: ..\\data\\corpuslow_13042021\\test.csv\n",
      "2021-04-18 18:02:42,804 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [00:01<00:00, 845.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 18:03:02,154 [b'0', b'1']\n",
      "Dictionary with 2 tags: 0, 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "data_folder = '../data/corpuslow_13042021'\n",
    "column_name_map = {1: \"text\", 2: \"label_topic\"}\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True) \n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 18:03:11,201 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,204 Model: \"TextClassifier(\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-04-18 18:03:11,205 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,206 Corpus: \"Corpus: 867 train + 108 dev + 109 test sentences\"\n",
      "2021-04-18 18:03:11,207 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,207 Parameters:\n",
      "2021-04-18 18:03:11,208  - learning_rate: \"3e-05\"\n",
      "2021-04-18 18:03:11,208  - mini_batch_size: \"16\"\n",
      "2021-04-18 18:03:11,209  - patience: \"3\"\n",
      "2021-04-18 18:03:11,209  - anneal_factor: \"0.5\"\n",
      "2021-04-18 18:03:11,210  - max_epochs: \"10\"\n",
      "2021-04-18 18:03:11,211  - shuffle: \"True\"\n",
      "2021-04-18 18:03:11,211  - train_with_dev: \"False\"\n",
      "2021-04-18 18:03:11,212  - batch_growth_annealing: \"False\"\n",
      "2021-04-18 18:03:11,213 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,213 Model training base path: \"flair\\transformers_low\"\n",
      "2021-04-18 18:03:11,214 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,215 Device: cuda\n",
      "2021-04-18 18:03:11,215 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:11,216 Embeddings storage mode: cpu\n",
      "2021-04-18 18:03:11,220 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:28,662 epoch 1 - iter 5/55 - loss 0.82296460 - samples/sec: 22.69 - lr: 0.000030\n",
      "2021-04-18 18:03:31,553 epoch 1 - iter 10/55 - loss 0.75950259 - samples/sec: 28.76 - lr: 0.000030\n",
      "2021-04-18 18:03:34,476 epoch 1 - iter 15/55 - loss 0.74985768 - samples/sec: 27.63 - lr: 0.000030\n",
      "2021-04-18 18:03:37,265 epoch 1 - iter 20/55 - loss 0.66867699 - samples/sec: 30.31 - lr: 0.000030\n",
      "2021-04-18 18:03:40,040 epoch 1 - iter 25/55 - loss 0.65651532 - samples/sec: 28.95 - lr: 0.000030\n",
      "2021-04-18 18:03:42,981 epoch 1 - iter 30/55 - loss 0.64261013 - samples/sec: 28.30 - lr: 0.000030\n",
      "2021-04-18 18:03:45,854 epoch 1 - iter 35/55 - loss 0.64638570 - samples/sec: 28.14 - lr: 0.000030\n",
      "2021-04-18 18:03:48,815 epoch 1 - iter 40/55 - loss 0.64048515 - samples/sec: 28.42 - lr: 0.000030\n",
      "2021-04-18 18:03:51,441 epoch 1 - iter 45/55 - loss 0.63548740 - samples/sec: 30.74 - lr: 0.000030\n",
      "2021-04-18 18:03:54,168 epoch 1 - iter 50/55 - loss 0.65869740 - samples/sec: 30.93 - lr: 0.000030\n",
      "2021-04-18 18:03:56,417 epoch 1 - iter 55/55 - loss 0.66185568 - samples/sec: 35.59 - lr: 0.000030\n",
      "2021-04-18 18:03:56,795 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:03:56,796 EPOCH 1 done: loss 0.6619 - lr 0.0000300\n",
      "2021-04-18 18:04:02,966 DEV : loss 0.6892048120498657 - score 0.5093\n",
      "2021-04-18 18:04:03,396 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 18:04:04,381 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:04:20,757 epoch 2 - iter 5/55 - loss 0.74526719 - samples/sec: 29.20 - lr: 0.000030\n",
      "2021-04-18 18:04:23,516 epoch 2 - iter 10/55 - loss 0.59645246 - samples/sec: 30.13 - lr: 0.000030\n",
      "2021-04-18 18:04:26,201 epoch 2 - iter 15/55 - loss 0.61112278 - samples/sec: 30.03 - lr: 0.000030\n",
      "2021-04-18 18:04:29,003 epoch 2 - iter 20/55 - loss 0.52216966 - samples/sec: 30.09 - lr: 0.000030\n",
      "2021-04-18 18:04:31,746 epoch 2 - iter 25/55 - loss 0.50222768 - samples/sec: 29.44 - lr: 0.000030\n",
      "2021-04-18 18:04:34,436 epoch 2 - iter 30/55 - loss 0.48779886 - samples/sec: 29.74 - lr: 0.000030\n",
      "2021-04-18 18:04:37,245 epoch 2 - iter 35/55 - loss 0.52038030 - samples/sec: 29.94 - lr: 0.000030\n",
      "2021-04-18 18:04:39,875 epoch 2 - iter 40/55 - loss 0.56191931 - samples/sec: 30.71 - lr: 0.000030\n",
      "2021-04-18 18:04:42,524 epoch 2 - iter 45/55 - loss 0.57578987 - samples/sec: 30.43 - lr: 0.000030\n",
      "2021-04-18 18:04:45,342 epoch 2 - iter 50/55 - loss 0.56286636 - samples/sec: 30.09 - lr: 0.000030\n",
      "2021-04-18 18:04:47,654 epoch 2 - iter 55/55 - loss 0.56961081 - samples/sec: 34.63 - lr: 0.000030\n",
      "2021-04-18 18:04:48,043 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:04:48,044 EPOCH 2 done: loss 0.5696 - lr 0.0000300\n",
      "2021-04-18 18:04:54,319 DEV : loss 0.6752293109893799 - score 0.713\n",
      "2021-04-18 18:04:54,755 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 18:04:55,757 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:05:12,086 epoch 3 - iter 5/55 - loss 0.33209084 - samples/sec: 28.68 - lr: 0.000030\n",
      "2021-04-18 18:05:14,932 epoch 3 - iter 10/55 - loss 0.35713962 - samples/sec: 29.18 - lr: 0.000030\n",
      "2021-04-18 18:05:17,662 epoch 3 - iter 15/55 - loss 0.38510621 - samples/sec: 29.58 - lr: 0.000030\n",
      "2021-04-18 18:05:20,505 epoch 3 - iter 20/55 - loss 0.39773590 - samples/sec: 29.33 - lr: 0.000030\n",
      "2021-04-18 18:05:23,395 epoch 3 - iter 25/55 - loss 0.37952818 - samples/sec: 27.92 - lr: 0.000030\n",
      "2021-04-18 18:05:26,233 epoch 3 - iter 30/55 - loss 0.40186019 - samples/sec: 29.48 - lr: 0.000030\n",
      "2021-04-18 18:05:28,924 epoch 3 - iter 35/55 - loss 0.42317367 - samples/sec: 30.02 - lr: 0.000030\n",
      "2021-04-18 18:05:31,935 epoch 3 - iter 40/55 - loss 0.40202472 - samples/sec: 27.79 - lr: 0.000030\n",
      "2021-04-18 18:05:34,771 epoch 3 - iter 45/55 - loss 0.39379371 - samples/sec: 28.44 - lr: 0.000030\n",
      "2021-04-18 18:05:37,682 epoch 3 - iter 50/55 - loss 0.39058439 - samples/sec: 27.64 - lr: 0.000030\n",
      "2021-04-18 18:05:40,179 epoch 3 - iter 55/55 - loss 0.38622909 - samples/sec: 33.84 - lr: 0.000030\n",
      "2021-04-18 18:05:40,574 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:05:40,576 EPOCH 3 done: loss 0.3862 - lr 0.0000300\n",
      "2021-04-18 18:05:46,621 DEV : loss 0.7566097378730774 - score 0.6296\n",
      "2021-04-18 18:05:47,126 BAD EPOCHS (no improvement): 1\n",
      "2021-04-18 18:05:47,128 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:06:03,512 epoch 4 - iter 5/55 - loss 0.14354820 - samples/sec: 29.99 - lr: 0.000030\n",
      "2021-04-18 18:06:06,334 epoch 4 - iter 10/55 - loss 0.22209441 - samples/sec: 29.53 - lr: 0.000030\n",
      "2021-04-18 18:06:08,989 epoch 4 - iter 15/55 - loss 0.17575452 - samples/sec: 30.41 - lr: 0.000030\n",
      "2021-04-18 18:06:11,715 epoch 4 - iter 20/55 - loss 0.13732880 - samples/sec: 30.72 - lr: 0.000030\n",
      "2021-04-18 18:06:14,325 epoch 4 - iter 25/55 - loss 0.20288371 - samples/sec: 30.85 - lr: 0.000030\n",
      "2021-04-18 18:06:16,939 epoch 4 - iter 30/55 - loss 0.19475862 - samples/sec: 30.86 - lr: 0.000030\n",
      "2021-04-18 18:06:19,653 epoch 4 - iter 35/55 - loss 0.18301080 - samples/sec: 30.92 - lr: 0.000030\n",
      "2021-04-18 18:06:22,296 epoch 4 - iter 40/55 - loss 0.16189741 - samples/sec: 30.57 - lr: 0.000030\n",
      "2021-04-18 18:06:25,053 epoch 4 - iter 45/55 - loss 0.15326011 - samples/sec: 30.48 - lr: 0.000030\n",
      "2021-04-18 18:06:27,683 epoch 4 - iter 50/55 - loss 0.16926748 - samples/sec: 30.57 - lr: 0.000030\n",
      "2021-04-18 18:06:29,949 epoch 4 - iter 55/55 - loss 0.16002019 - samples/sec: 35.56 - lr: 0.000030\n",
      "2021-04-18 18:06:30,328 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:06:30,329 EPOCH 4 done: loss 0.1600 - lr 0.0000300\n",
      "2021-04-18 18:06:36,355 DEV : loss 1.3616418838500977 - score 0.6204\n",
      "2021-04-18 18:06:36,767 BAD EPOCHS (no improvement): 2\n",
      "2021-04-18 18:06:36,768 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:06:53,122 epoch 5 - iter 5/55 - loss 0.07980564 - samples/sec: 28.85 - lr: 0.000030\n",
      "2021-04-18 18:06:55,817 epoch 5 - iter 10/55 - loss 0.04120182 - samples/sec: 29.98 - lr: 0.000030\n",
      "2021-04-18 18:06:58,761 epoch 5 - iter 15/55 - loss 0.10102808 - samples/sec: 28.60 - lr: 0.000030\n",
      "2021-04-18 18:07:01,433 epoch 5 - iter 20/55 - loss 0.09267689 - samples/sec: 30.22 - lr: 0.000030\n",
      "2021-04-18 18:07:04,059 epoch 5 - iter 25/55 - loss 0.07439196 - samples/sec: 30.57 - lr: 0.000030\n",
      "2021-04-18 18:07:06,793 epoch 5 - iter 30/55 - loss 0.07573475 - samples/sec: 30.63 - lr: 0.000030\n",
      "2021-04-18 18:07:09,459 epoch 5 - iter 35/55 - loss 0.06517255 - samples/sec: 30.32 - lr: 0.000030\n",
      "2021-04-18 18:07:12,215 epoch 5 - iter 40/55 - loss 0.05757075 - samples/sec: 30.48 - lr: 0.000030\n",
      "2021-04-18 18:07:14,825 epoch 5 - iter 45/55 - loss 0.07844634 - samples/sec: 30.95 - lr: 0.000030\n",
      "2021-04-18 18:07:17,529 epoch 5 - iter 50/55 - loss 0.09177440 - samples/sec: 31.06 - lr: 0.000030\n",
      "2021-04-18 18:07:19,810 epoch 5 - iter 55/55 - loss 0.09094008 - samples/sec: 35.11 - lr: 0.000030\n",
      "2021-04-18 18:07:20,193 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:07:20,194 EPOCH 5 done: loss 0.0909 - lr 0.0000300\n",
      "2021-04-18 18:07:26,219 DEV : loss 2.7026331424713135 - score 0.713\n",
      "2021-04-18 18:07:26,722 BAD EPOCHS (no improvement): 3\n",
      "2021-04-18 18:07:26,724 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:07:42,707 epoch 6 - iter 5/55 - loss 0.06770533 - samples/sec: 30.29 - lr: 0.000030\n",
      "2021-04-18 18:07:45,373 epoch 6 - iter 10/55 - loss 0.07628950 - samples/sec: 31.22 - lr: 0.000030\n",
      "2021-04-18 18:07:48,010 epoch 6 - iter 15/55 - loss 0.05523398 - samples/sec: 30.59 - lr: 0.000030\n",
      "2021-04-18 18:07:50,799 epoch 6 - iter 20/55 - loss 0.04374209 - samples/sec: 30.15 - lr: 0.000030\n",
      "2021-04-18 18:07:53,555 epoch 6 - iter 25/55 - loss 0.03837650 - samples/sec: 29.19 - lr: 0.000030\n",
      "2021-04-18 18:07:56,241 epoch 6 - iter 30/55 - loss 0.03400338 - samples/sec: 29.91 - lr: 0.000030\n",
      "2021-04-18 18:07:59,071 epoch 6 - iter 35/55 - loss 0.03263249 - samples/sec: 29.70 - lr: 0.000030\n",
      "2021-04-18 18:08:01,691 epoch 6 - iter 40/55 - loss 0.02873416 - samples/sec: 30.77 - lr: 0.000030\n",
      "2021-04-18 18:08:04,413 epoch 6 - iter 45/55 - loss 0.04371793 - samples/sec: 30.89 - lr: 0.000030\n",
      "2021-04-18 18:08:07,047 epoch 6 - iter 50/55 - loss 0.03943655 - samples/sec: 30.70 - lr: 0.000030\n",
      "2021-04-18 18:08:09,373 epoch 6 - iter 55/55 - loss 0.03588918 - samples/sec: 34.42 - lr: 0.000030\n",
      "2021-04-18 18:08:09,763 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:08:09,764 EPOCH 6 done: loss 0.0359 - lr 0.0000300\n",
      "2021-04-18 18:08:15,840 DEV : loss 2.0507822036743164 - score 0.6574\n",
      "Epoch     6: reducing learning rate of group 0 to 1.5000e-05.\n",
      "2021-04-18 18:08:16,251 BAD EPOCHS (no improvement): 4\n",
      "2021-04-18 18:08:16,252 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:08:32,242 epoch 7 - iter 5/55 - loss 0.01551867 - samples/sec: 30.49 - lr: 0.000015\n",
      "2021-04-18 18:08:34,872 epoch 7 - iter 10/55 - loss 0.00801493 - samples/sec: 30.64 - lr: 0.000015\n",
      "2021-04-18 18:08:37,629 epoch 7 - iter 15/55 - loss 0.00539967 - samples/sec: 30.32 - lr: 0.000015\n",
      "2021-04-18 18:08:40,253 epoch 7 - iter 20/55 - loss 0.00411711 - samples/sec: 30.75 - lr: 0.000015\n",
      "2021-04-18 18:08:42,873 epoch 7 - iter 25/55 - loss 0.01000637 - samples/sec: 30.70 - lr: 0.000015\n",
      "2021-04-18 18:08:45,640 epoch 7 - iter 30/55 - loss 0.00835491 - samples/sec: 30.29 - lr: 0.000015\n",
      "2021-04-18 18:08:48,270 epoch 7 - iter 35/55 - loss 0.00817877 - samples/sec: 30.71 - lr: 0.000015\n",
      "2021-04-18 18:08:50,976 epoch 7 - iter 40/55 - loss 0.00717154 - samples/sec: 30.93 - lr: 0.000015\n",
      "2021-04-18 18:08:53,552 epoch 7 - iter 45/55 - loss 0.00655245 - samples/sec: 31.27 - lr: 0.000015\n",
      "2021-04-18 18:08:56,299 epoch 7 - iter 50/55 - loss 0.00592602 - samples/sec: 30.46 - lr: 0.000015\n",
      "2021-04-18 18:08:58,590 epoch 7 - iter 55/55 - loss 0.00541448 - samples/sec: 35.14 - lr: 0.000015\n",
      "2021-04-18 18:08:58,975 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:08:58,976 EPOCH 7 done: loss 0.0054 - lr 0.0000150\n",
      "2021-04-18 18:09:04,995 DEV : loss 2.173786163330078 - score 0.6944\n",
      "2021-04-18 18:09:05,406 BAD EPOCHS (no improvement): 1\n",
      "2021-04-18 18:09:05,408 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:09:21,441 epoch 8 - iter 5/55 - loss 0.00019678 - samples/sec: 30.19 - lr: 0.000015\n",
      "2021-04-18 18:09:24,050 epoch 8 - iter 10/55 - loss 0.00011860 - samples/sec: 30.72 - lr: 0.000015\n",
      "2021-04-18 18:09:26,686 epoch 8 - iter 15/55 - loss 0.00008909 - samples/sec: 30.66 - lr: 0.000015\n",
      "2021-04-18 18:09:29,438 epoch 8 - iter 20/55 - loss 0.00011924 - samples/sec: 30.82 - lr: 0.000015\n",
      "2021-04-18 18:09:32,075 epoch 8 - iter 25/55 - loss 0.00050326 - samples/sec: 30.61 - lr: 0.000015\n",
      "2021-04-18 18:09:34,735 epoch 8 - iter 30/55 - loss 0.00044913 - samples/sec: 30.08 - lr: 0.000015\n",
      "2021-04-18 18:09:37,468 epoch 8 - iter 35/55 - loss 0.00040872 - samples/sec: 30.75 - lr: 0.000015\n",
      "2021-04-18 18:09:40,092 epoch 8 - iter 40/55 - loss 0.00036463 - samples/sec: 30.79 - lr: 0.000015\n",
      "2021-04-18 18:09:42,903 epoch 8 - iter 45/55 - loss 0.00032796 - samples/sec: 29.86 - lr: 0.000015\n",
      "2021-04-18 18:09:45,515 epoch 8 - iter 50/55 - loss 0.00032829 - samples/sec: 30.92 - lr: 0.000015\n",
      "2021-04-18 18:09:47,735 epoch 8 - iter 55/55 - loss 0.00030874 - samples/sec: 36.04 - lr: 0.000015\n",
      "2021-04-18 18:09:48,118 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:09:48,119 EPOCH 8 done: loss 0.0003 - lr 0.0000150\n",
      "2021-04-18 18:09:54,241 DEV : loss 2.1932008266448975 - score 0.6944\n",
      "2021-04-18 18:09:54,651 BAD EPOCHS (no improvement): 2\n",
      "2021-04-18 18:09:54,652 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:10:10,633 epoch 9 - iter 5/55 - loss 0.00044143 - samples/sec: 31.06 - lr: 0.000015\n",
      "2021-04-18 18:10:13,292 epoch 9 - iter 10/55 - loss 0.00023847 - samples/sec: 30.34 - lr: 0.000015\n",
      "2021-04-18 18:10:16,029 epoch 9 - iter 15/55 - loss 0.00016350 - samples/sec: 30.59 - lr: 0.000015\n",
      "2021-04-18 18:10:18,656 epoch 9 - iter 20/55 - loss 0.00018868 - samples/sec: 30.79 - lr: 0.000015\n",
      "2021-04-18 18:10:21,269 epoch 9 - iter 25/55 - loss 0.00015818 - samples/sec: 30.75 - lr: 0.000015\n",
      "2021-04-18 18:10:23,992 epoch 9 - iter 30/55 - loss 0.00013353 - samples/sec: 30.89 - lr: 0.000015\n",
      "2021-04-18 18:10:26,653 epoch 9 - iter 35/55 - loss 0.00012758 - samples/sec: 30.37 - lr: 0.000015\n",
      "2021-04-18 18:10:29,414 epoch 9 - iter 40/55 - loss 0.00011797 - samples/sec: 30.19 - lr: 0.000015\n",
      "2021-04-18 18:10:32,093 epoch 9 - iter 45/55 - loss 0.00010599 - samples/sec: 30.14 - lr: 0.000015\n",
      "2021-04-18 18:10:34,859 epoch 9 - iter 50/55 - loss 0.00012247 - samples/sec: 30.35 - lr: 0.000015\n",
      "2021-04-18 18:10:37,124 epoch 9 - iter 55/55 - loss 0.00011371 - samples/sec: 35.40 - lr: 0.000015\n",
      "2021-04-18 18:10:37,496 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:10:37,497 EPOCH 9 done: loss 0.0001 - lr 0.0000150\n",
      "2021-04-18 18:10:43,403 DEV : loss 2.3451409339904785 - score 0.7222\n",
      "2021-04-18 18:10:43,814 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 18:10:44,755 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 18:11:01,223 epoch 10 - iter 5/55 - loss 0.00006539 - samples/sec: 29.64 - lr: 0.000015\n",
      "2021-04-18 18:11:03,928 epoch 10 - iter 10/55 - loss 0.00004236 - samples/sec: 30.71 - lr: 0.000015\n",
      "2021-04-18 18:11:06,652 epoch 10 - iter 15/55 - loss 0.00004745 - samples/sec: 29.63 - lr: 0.000015\n",
      "2021-04-18 18:11:09,453 epoch 10 - iter 20/55 - loss 0.00005056 - samples/sec: 30.14 - lr: 0.000015\n"
     ]
    }
   ],
   "source": [
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('./flair/transformers_low',\n",
    "              learning_rate=3e-5, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=10) # terminate after 5 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
