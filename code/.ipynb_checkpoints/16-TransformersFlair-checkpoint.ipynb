{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main resource: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "flair.device = device\n",
    "\n",
    "print(flair.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 16:30:48,905 Reading data from ..\\data\\corpus_10042021\n",
      "2021-04-18 16:30:48,953 Train: ..\\data\\corpus_10042021\\train.csv\n",
      "2021-04-18 16:30:48,953 Dev: ..\\data\\corpus_10042021\\dev.csv\n",
      "2021-04-18 16:30:48,954 Test: ..\\data\\corpus_10042021\\test.csv\n",
      "2021-04-18 16:30:48,989 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 976/976 [00:01<00:00, 863.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 16:31:08,157 [b'High', b'Low', b'Medium']\n",
      "Dictionary with 3 tags: High, Low, Medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "data_folder = '../data/corpus_10042021'\n",
    "column_name_map = {1: \"text\", 2: \"label_topic\"}\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True) \n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee5b29a0e8446ef88f6a8c9f828f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0381492e67843f2a1f298cf16605d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1982fe6a6d0941e1b5fed82eec3cda3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec35d40d7344475b5e4c02b2fe5eb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d71ff88d194ea7a0e5f2dc8b60246d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 16:48:34,774 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,777 Model: \"TextClassifier(\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-04-18 16:48:34,778 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,778 Corpus: \"Corpus: 867 train + 108 dev + 109 test sentences\"\n",
      "2021-04-18 16:48:34,779 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,780 Parameters:\n",
      "2021-04-18 16:48:34,780  - learning_rate: \"3e-05\"\n",
      "2021-04-18 16:48:34,781  - mini_batch_size: \"4\"\n",
      "2021-04-18 16:48:34,782  - patience: \"3\"\n",
      "2021-04-18 16:48:34,782  - anneal_factor: \"0.5\"\n",
      "2021-04-18 16:48:34,783  - max_epochs: \"10\"\n",
      "2021-04-18 16:48:34,784  - shuffle: \"True\"\n",
      "2021-04-18 16:48:34,785  - train_with_dev: \"False\"\n",
      "2021-04-18 16:48:34,785  - batch_growth_annealing: \"False\"\n",
      "2021-04-18 16:48:34,786 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,787 Model training base path: \"flair_xlnet\"\n",
      "2021-04-18 16:48:34,788 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,788 Device: cuda\n",
      "2021-04-18 16:48:34,789 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:34,790 Embeddings storage mode: cpu\n",
      "2021-04-18 16:48:34,793 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:48:53,427 epoch 1 - iter 21/217 - loss 1.23537178 - samples/sec: 17.04 - lr: 0.000030\n",
      "2021-04-18 16:48:57,180 epoch 1 - iter 42/217 - loss 1.15947356 - samples/sec: 22.55 - lr: 0.000030\n",
      "2021-04-18 16:49:00,995 epoch 1 - iter 63/217 - loss 1.14460753 - samples/sec: 23.23 - lr: 0.000030\n",
      "2021-04-18 16:49:04,638 epoch 1 - iter 84/217 - loss 1.13588822 - samples/sec: 23.21 - lr: 0.000030\n",
      "2021-04-18 16:49:08,307 epoch 1 - iter 105/217 - loss 1.12976388 - samples/sec: 23.14 - lr: 0.000030\n",
      "2021-04-18 16:49:12,092 epoch 1 - iter 126/217 - loss 1.11456972 - samples/sec: 23.11 - lr: 0.000030\n",
      "2021-04-18 16:49:15,780 epoch 1 - iter 147/217 - loss 1.10826726 - samples/sec: 22.99 - lr: 0.000030\n",
      "2021-04-18 16:49:19,444 epoch 1 - iter 168/217 - loss 1.10097413 - samples/sec: 23.11 - lr: 0.000030\n",
      "2021-04-18 16:49:23,425 epoch 1 - iter 189/217 - loss 1.09671044 - samples/sec: 21.95 - lr: 0.000030\n",
      "2021-04-18 16:49:27,057 epoch 1 - iter 210/217 - loss 1.10017644 - samples/sec: 23.31 - lr: 0.000030\n",
      "2021-04-18 16:49:28,672 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:49:28,673 EPOCH 1 done: loss 1.1069 - lr 0.0000300\n",
      "2021-04-18 16:49:34,425 DEV : loss 1.0516793727874756 - score 0.4259\n",
      "2021-04-18 16:49:34,948 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 16:49:35,893 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:49:53,081 epoch 2 - iter 21/217 - loss 0.95700955 - samples/sec: 22.94 - lr: 0.000030\n",
      "2021-04-18 16:49:56,967 epoch 2 - iter 42/217 - loss 0.92785516 - samples/sec: 21.80 - lr: 0.000030\n",
      "2021-04-18 16:50:00,815 epoch 2 - iter 63/217 - loss 1.10759416 - samples/sec: 22.61 - lr: 0.000030\n",
      "2021-04-18 16:50:04,446 epoch 2 - iter 84/217 - loss 1.09888196 - samples/sec: 23.31 - lr: 0.000030\n",
      "2021-04-18 16:50:08,103 epoch 2 - iter 105/217 - loss 1.07017046 - samples/sec: 23.16 - lr: 0.000030\n",
      "2021-04-18 16:50:11,904 epoch 2 - iter 126/217 - loss 1.04541653 - samples/sec: 23.02 - lr: 0.000030\n",
      "2021-04-18 16:50:15,597 epoch 2 - iter 147/217 - loss 1.05558489 - samples/sec: 22.94 - lr: 0.000030\n",
      "2021-04-18 16:50:19,352 epoch 2 - iter 168/217 - loss 1.04338469 - samples/sec: 22.55 - lr: 0.000030\n",
      "2021-04-18 16:50:23,092 epoch 2 - iter 189/217 - loss 1.04282523 - samples/sec: 22.62 - lr: 0.000030\n",
      "2021-04-18 16:50:27,011 epoch 2 - iter 210/217 - loss 1.04695815 - samples/sec: 22.33 - lr: 0.000030\n",
      "2021-04-18 16:50:28,623 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:50:28,624 EPOCH 2 done: loss 1.0479 - lr 0.0000300\n",
      "2021-04-18 16:50:34,279 DEV : loss 1.17844557762146 - score 0.4259\n",
      "2021-04-18 16:50:34,717 BAD EPOCHS (no improvement): 1\n",
      "2021-04-18 16:50:34,718 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:50:52,091 epoch 3 - iter 21/217 - loss 0.82885513 - samples/sec: 22.89 - lr: 0.000030\n",
      "2021-04-18 16:50:55,688 epoch 3 - iter 42/217 - loss 0.80610938 - samples/sec: 23.54 - lr: 0.000030\n",
      "2021-04-18 16:50:59,390 epoch 3 - iter 63/217 - loss 0.81489212 - samples/sec: 22.83 - lr: 0.000030\n",
      "2021-04-18 16:51:03,193 epoch 3 - iter 84/217 - loss 0.77789345 - samples/sec: 23.03 - lr: 0.000030\n",
      "2021-04-18 16:51:06,862 epoch 3 - iter 105/217 - loss 0.75322833 - samples/sec: 23.05 - lr: 0.000030\n",
      "2021-04-18 16:51:10,613 epoch 3 - iter 126/217 - loss 0.78241589 - samples/sec: 22.57 - lr: 0.000030\n",
      "2021-04-18 16:51:14,487 epoch 3 - iter 147/217 - loss 0.80586248 - samples/sec: 22.59 - lr: 0.000030\n",
      "2021-04-18 16:51:18,285 epoch 3 - iter 168/217 - loss 0.80320634 - samples/sec: 22.29 - lr: 0.000030\n",
      "2021-04-18 16:51:22,119 epoch 3 - iter 189/217 - loss 0.79010211 - samples/sec: 22.73 - lr: 0.000030\n",
      "2021-04-18 16:51:25,760 epoch 3 - iter 210/217 - loss 0.77882512 - samples/sec: 23.24 - lr: 0.000030\n",
      "2021-04-18 16:51:27,304 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:51:27,305 EPOCH 3 done: loss 0.7804 - lr 0.0000300\n",
      "2021-04-18 16:51:32,872 DEV : loss 1.6175380945205688 - score 0.4074\n",
      "2021-04-18 16:51:33,400 BAD EPOCHS (no improvement): 2\n",
      "2021-04-18 16:51:33,402 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:51:50,231 epoch 4 - iter 21/217 - loss 0.45294796 - samples/sec: 23.63 - lr: 0.000030\n",
      "2021-04-18 16:51:53,828 epoch 4 - iter 42/217 - loss 0.37878374 - samples/sec: 23.56 - lr: 0.000030\n",
      "2021-04-18 16:51:57,565 epoch 4 - iter 63/217 - loss 0.34611853 - samples/sec: 23.31 - lr: 0.000030\n",
      "2021-04-18 16:52:01,255 epoch 4 - iter 84/217 - loss 0.37309775 - samples/sec: 22.93 - lr: 0.000030\n",
      "2021-04-18 16:52:04,909 epoch 4 - iter 105/217 - loss 0.35907085 - samples/sec: 23.23 - lr: 0.000030\n",
      "2021-04-18 16:52:08,604 epoch 4 - iter 126/217 - loss 0.40078787 - samples/sec: 22.89 - lr: 0.000030\n",
      "2021-04-18 16:52:12,432 epoch 4 - iter 147/217 - loss 0.39949012 - samples/sec: 22.84 - lr: 0.000030\n",
      "2021-04-18 16:52:16,026 epoch 4 - iter 168/217 - loss 0.38456164 - samples/sec: 23.58 - lr: 0.000030\n",
      "2021-04-18 16:52:19,606 epoch 4 - iter 189/217 - loss 0.37910582 - samples/sec: 23.71 - lr: 0.000030\n",
      "2021-04-18 16:52:23,207 epoch 4 - iter 210/217 - loss 0.36742262 - samples/sec: 23.52 - lr: 0.000030\n",
      "2021-04-18 16:52:24,885 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:52:24,887 EPOCH 4 done: loss 0.3641 - lr 0.0000300\n",
      "2021-04-18 16:52:30,448 DEV : loss 2.8741862773895264 - score 0.4074\n",
      "2021-04-18 16:52:30,884 BAD EPOCHS (no improvement): 3\n",
      "2021-04-18 16:52:30,886 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:52:47,873 epoch 5 - iter 21/217 - loss 0.26711686 - samples/sec: 23.55 - lr: 0.000030\n",
      "2021-04-18 16:52:51,511 epoch 5 - iter 42/217 - loss 0.15822241 - samples/sec: 23.28 - lr: 0.000030\n",
      "2021-04-18 16:52:55,139 epoch 5 - iter 63/217 - loss 0.13109191 - samples/sec: 23.34 - lr: 0.000030\n",
      "2021-04-18 16:52:58,766 epoch 5 - iter 84/217 - loss 0.12016020 - samples/sec: 23.37 - lr: 0.000030\n",
      "2021-04-18 16:53:02,561 epoch 5 - iter 105/217 - loss 0.13122208 - samples/sec: 23.18 - lr: 0.000030\n",
      "2021-04-18 16:53:06,117 epoch 5 - iter 126/217 - loss 0.12278285 - samples/sec: 23.82 - lr: 0.000030\n",
      "2021-04-18 16:53:09,756 epoch 5 - iter 147/217 - loss 0.12011034 - samples/sec: 23.29 - lr: 0.000030\n",
      "2021-04-18 16:53:13,324 epoch 5 - iter 168/217 - loss 0.11216584 - samples/sec: 23.74 - lr: 0.000030\n",
      "2021-04-18 16:53:17,066 epoch 5 - iter 189/217 - loss 0.11427669 - samples/sec: 23.35 - lr: 0.000030\n",
      "2021-04-18 16:53:20,676 epoch 5 - iter 210/217 - loss 0.11672987 - samples/sec: 23.48 - lr: 0.000030\n",
      "2021-04-18 16:53:22,273 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:53:22,274 EPOCH 5 done: loss 0.1156 - lr 0.0000300\n",
      "2021-04-18 16:53:27,821 DEV : loss 3.242818593978882 - score 0.5093\n",
      "2021-04-18 16:53:28,255 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 16:53:29,212 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:53:46,416 epoch 6 - iter 21/217 - loss 0.00894430 - samples/sec: 23.43 - lr: 0.000030\n",
      "2021-04-18 16:53:50,089 epoch 6 - iter 42/217 - loss 0.00465115 - samples/sec: 23.05 - lr: 0.000030\n",
      "2021-04-18 16:53:53,890 epoch 6 - iter 63/217 - loss 0.00662751 - samples/sec: 22.89 - lr: 0.000030\n",
      "2021-04-18 16:53:57,711 epoch 6 - iter 84/217 - loss 0.01830843 - samples/sec: 22.17 - lr: 0.000030\n",
      "2021-04-18 16:54:01,399 epoch 6 - iter 105/217 - loss 0.02293141 - samples/sec: 22.98 - lr: 0.000030\n",
      "2021-04-18 16:54:05,266 epoch 6 - iter 126/217 - loss 0.03327576 - samples/sec: 22.58 - lr: 0.000030\n",
      "2021-04-18 16:54:08,893 epoch 6 - iter 147/217 - loss 0.04022134 - samples/sec: 23.39 - lr: 0.000030\n",
      "2021-04-18 16:54:12,463 epoch 6 - iter 168/217 - loss 0.04505115 - samples/sec: 23.72 - lr: 0.000030\n",
      "2021-04-18 16:54:16,101 epoch 6 - iter 189/217 - loss 0.04949839 - samples/sec: 23.32 - lr: 0.000030\n",
      "2021-04-18 16:54:19,770 epoch 6 - iter 210/217 - loss 0.04688915 - samples/sec: 23.80 - lr: 0.000030\n",
      "2021-04-18 16:54:21,313 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:54:21,314 EPOCH 6 done: loss 0.0474 - lr 0.0000300\n",
      "2021-04-18 16:54:26,963 DEV : loss 4.196915626525879 - score 0.4352\n",
      "2021-04-18 16:54:27,406 BAD EPOCHS (no improvement): 1\n",
      "2021-04-18 16:54:27,407 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:54:44,524 epoch 7 - iter 21/217 - loss 0.00159756 - samples/sec: 22.68 - lr: 0.000030\n",
      "2021-04-18 16:54:48,128 epoch 7 - iter 42/217 - loss 0.00549900 - samples/sec: 23.50 - lr: 0.000030\n",
      "2021-04-18 16:54:51,642 epoch 7 - iter 63/217 - loss 0.00376744 - samples/sec: 24.11 - lr: 0.000030\n",
      "2021-04-18 16:54:55,287 epoch 7 - iter 84/217 - loss 0.02553243 - samples/sec: 23.90 - lr: 0.000030\n",
      "2021-04-18 16:54:58,870 epoch 7 - iter 105/217 - loss 0.02055639 - samples/sec: 23.70 - lr: 0.000030\n",
      "2021-04-18 16:55:02,388 epoch 7 - iter 126/217 - loss 0.01779858 - samples/sec: 24.06 - lr: 0.000030\n",
      "2021-04-18 16:55:05,949 epoch 7 - iter 147/217 - loss 0.01537154 - samples/sec: 23.82 - lr: 0.000030\n",
      "2021-04-18 16:55:09,769 epoch 7 - iter 168/217 - loss 0.01471690 - samples/sec: 22.86 - lr: 0.000030\n",
      "2021-04-18 16:55:13,401 epoch 7 - iter 189/217 - loss 0.01360205 - samples/sec: 23.37 - lr: 0.000030\n",
      "2021-04-18 16:55:17,043 epoch 7 - iter 210/217 - loss 0.01320303 - samples/sec: 23.22 - lr: 0.000030\n",
      "2021-04-18 16:55:18,574 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:55:18,575 EPOCH 7 done: loss 0.0128 - lr 0.0000300\n",
      "2021-04-18 16:55:24,247 DEV : loss 4.7205705642700195 - score 0.4722\n",
      "2021-04-18 16:55:24,687 BAD EPOCHS (no improvement): 2\n",
      "2021-04-18 16:55:24,689 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:55:41,576 epoch 8 - iter 21/217 - loss 0.00015977 - samples/sec: 23.85 - lr: 0.000030\n",
      "2021-04-18 16:55:45,226 epoch 8 - iter 42/217 - loss 0.00640752 - samples/sec: 23.81 - lr: 0.000030\n",
      "2021-04-18 16:55:48,782 epoch 8 - iter 63/217 - loss 0.00439867 - samples/sec: 23.88 - lr: 0.000030\n",
      "2021-04-18 16:55:52,304 epoch 8 - iter 84/217 - loss 0.00353141 - samples/sec: 24.06 - lr: 0.000030\n",
      "2021-04-18 16:55:55,968 epoch 8 - iter 105/217 - loss 0.02870405 - samples/sec: 23.14 - lr: 0.000030\n",
      "2021-04-18 16:55:59,733 epoch 8 - iter 126/217 - loss 0.03153306 - samples/sec: 23.22 - lr: 0.000030\n",
      "2021-04-18 16:56:03,272 epoch 8 - iter 147/217 - loss 0.02849142 - samples/sec: 23.94 - lr: 0.000030\n",
      "2021-04-18 16:56:06,865 epoch 8 - iter 168/217 - loss 0.02494572 - samples/sec: 23.57 - lr: 0.000030\n",
      "2021-04-18 16:56:10,455 epoch 8 - iter 189/217 - loss 0.02218448 - samples/sec: 23.66 - lr: 0.000030\n",
      "2021-04-18 16:56:14,147 epoch 8 - iter 210/217 - loss 0.01999528 - samples/sec: 23.67 - lr: 0.000030\n",
      "2021-04-18 16:56:15,687 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:56:15,688 EPOCH 8 done: loss 0.0194 - lr 0.0000300\n",
      "2021-04-18 16:56:21,269 DEV : loss 4.628772258758545 - score 0.4352\n",
      "2021-04-18 16:56:21,699 BAD EPOCHS (no improvement): 3\n",
      "2021-04-18 16:56:21,701 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:56:38,661 epoch 9 - iter 21/217 - loss 0.00053933 - samples/sec: 23.90 - lr: 0.000030\n",
      "2021-04-18 16:56:42,285 epoch 9 - iter 42/217 - loss 0.00100689 - samples/sec: 23.37 - lr: 0.000030\n",
      "2021-04-18 16:56:45,900 epoch 9 - iter 63/217 - loss 0.00188657 - samples/sec: 23.41 - lr: 0.000030\n",
      "2021-04-18 16:56:49,604 epoch 9 - iter 84/217 - loss 0.00142518 - samples/sec: 23.55 - lr: 0.000030\n",
      "2021-04-18 16:56:53,150 epoch 9 - iter 105/217 - loss 0.00156714 - samples/sec: 23.89 - lr: 0.000030\n",
      "2021-04-18 16:56:56,776 epoch 9 - iter 126/217 - loss 0.00133064 - samples/sec: 23.34 - lr: 0.000030\n",
      "2021-04-18 16:57:00,584 epoch 9 - iter 147/217 - loss 0.00116023 - samples/sec: 23.08 - lr: 0.000030\n",
      "2021-04-18 16:57:04,229 epoch 9 - iter 168/217 - loss 0.00103879 - samples/sec: 23.19 - lr: 0.000030\n",
      "2021-04-18 16:57:07,863 epoch 9 - iter 189/217 - loss 0.00094890 - samples/sec: 23.34 - lr: 0.000030\n",
      "2021-04-18 16:57:11,708 epoch 9 - iter 210/217 - loss 0.00089914 - samples/sec: 22.02 - lr: 0.000030\n",
      "2021-04-18 16:57:13,554 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:57:13,555 EPOCH 9 done: loss 0.0009 - lr 0.0000300\n",
      "2021-04-18 16:57:19,941 DEV : loss 5.626125335693359 - score 0.4722\n",
      "Epoch     9: reducing learning rate of group 0 to 1.5000e-05.\n",
      "2021-04-18 16:57:20,423 BAD EPOCHS (no improvement): 4\n",
      "2021-04-18 16:57:20,424 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:57:38,027 epoch 10 - iter 21/217 - loss 0.00012465 - samples/sec: 22.65 - lr: 0.000015\n",
      "2021-04-18 16:57:41,969 epoch 10 - iter 42/217 - loss 0.00007297 - samples/sec: 21.47 - lr: 0.000015\n",
      "2021-04-18 16:57:46,158 epoch 10 - iter 63/217 - loss 0.00670129 - samples/sec: 20.79 - lr: 0.000015\n",
      "2021-04-18 16:57:49,999 epoch 10 - iter 84/217 - loss 0.00503226 - samples/sec: 22.02 - lr: 0.000015\n",
      "2021-04-18 16:57:53,585 epoch 10 - iter 105/217 - loss 0.00441063 - samples/sec: 23.61 - lr: 0.000015\n",
      "2021-04-18 16:57:57,171 epoch 10 - iter 126/217 - loss 0.00370545 - samples/sec: 23.62 - lr: 0.000015\n",
      "2021-04-18 16:58:00,990 epoch 10 - iter 147/217 - loss 0.00330468 - samples/sec: 22.85 - lr: 0.000015\n",
      "2021-04-18 16:58:04,904 epoch 10 - iter 168/217 - loss 0.00289271 - samples/sec: 21.62 - lr: 0.000015\n",
      "2021-04-18 16:58:08,974 epoch 10 - iter 189/217 - loss 0.00257657 - samples/sec: 20.80 - lr: 0.000015\n",
      "2021-04-18 16:58:13,092 epoch 10 - iter 210/217 - loss 0.00233493 - samples/sec: 21.20 - lr: 0.000015\n",
      "2021-04-18 16:58:14,814 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:58:14,815 EPOCH 10 done: loss 0.0023 - lr 0.0000150\n",
      "2021-04-18 16:58:20,840 DEV : loss 5.3988423347473145 - score 0.4352\n",
      "2021-04-18 16:58:21,283 BAD EPOCHS (no improvement): 1\n",
      "2021-04-18 16:58:22,228 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 16:58:22,229 Testing using best model ...\n",
      "2021-04-18 16:58:22,231 loading file flair_xlnet\\best-model.pt\n",
      "2021-04-18 16:58:37,398 \t0.422\n",
      "2021-04-18 16:58:37,400 \n",
      "Results:\n",
      "- F-score (micro) 0.422\n",
      "- F-score (macro) 0.4034\n",
      "- Accuracy 0.422\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High     0.3684    0.2593    0.3043        27\n",
      "         Low     0.4314    0.6111    0.5057        36\n",
      "      Medium     0.4359    0.3696    0.4000        46\n",
      "\n",
      "   micro avg     0.4220    0.4220    0.4220       109\n",
      "   macro avg     0.4119    0.4133    0.4034       109\n",
      "weighted avg     0.4177    0.4220    0.4112       109\n",
      " samples avg     0.4220    0.4220    0.4220       109\n",
      "\n",
      "2021-04-18 16:58:37,400 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.422,\n",
       " 'dev_score_history': [0.4259,\n",
       "  0.4259,\n",
       "  0.4074,\n",
       "  0.4074,\n",
       "  0.5093,\n",
       "  0.4352,\n",
       "  0.4722,\n",
       "  0.4352,\n",
       "  0.4722,\n",
       "  0.4352],\n",
       " 'train_loss_history': [1.106940983764587,\n",
       "  1.0478954512265422,\n",
       "  0.7803794679254473,\n",
       "  0.3641364173836085,\n",
       "  0.1156075713953646,\n",
       "  0.04744413032194318,\n",
       "  0.012784025995174052,\n",
       "  0.019352154888300978,\n",
       "  0.0008776853299023337,\n",
       "  0.002259977813497576],\n",
       " 'dev_loss_history': [1.0516793727874756,\n",
       "  1.17844557762146,\n",
       "  1.6175380945205688,\n",
       "  2.8741862773895264,\n",
       "  3.242818593978882,\n",
       "  4.196915626525879,\n",
       "  4.7205705642700195,\n",
       "  4.628772258758545,\n",
       "  5.626125335693359,\n",
       "  5.3988423347473145]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('./flair/transformers',\n",
    "              learning_rate=3e-5, # use very small learning rate\n",
    "              mini_batch_size=4,\n",
    "              mini_batch_chunk_size=2, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=10) # terminate after 10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
