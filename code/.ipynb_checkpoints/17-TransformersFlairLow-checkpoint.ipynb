{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main resource: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "flair.device = device\n",
    "\n",
    "print(flair.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:45:47,591 Reading data from ..\\data\\corpuslow_13042021\n",
      "2021-04-18 17:45:47,592 Train: ..\\data\\corpuslow_13042021\\train.csv\n",
      "2021-04-18 17:45:47,592 Dev: ..\\data\\corpuslow_13042021\\dev.csv\n",
      "2021-04-18 17:45:47,593 Test: ..\\data\\corpuslow_13042021\\test.csv\n",
      "2021-04-18 17:45:47,627 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 976/976 [00:01<00:00, 864.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:46:06,960 [b'0', b'1']\n",
      "Dictionary with 2 tags: 0, 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "data_folder = '../data/corpuslow_13042021'\n",
    "column_name_map = {1: \"text\", 2: \"label_topic\"}\n",
    "\n",
    "# 1. get the corpus\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True) \n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:46:16,851 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,854 Model: \"TextClassifier(\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-04-18 17:46:16,855 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,856 Corpus: \"Corpus: 867 train + 108 dev + 109 test sentences\"\n",
      "2021-04-18 17:46:16,856 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,857 Parameters:\n",
      "2021-04-18 17:46:16,858  - learning_rate: \"3e-05\"\n",
      "2021-04-18 17:46:16,859  - mini_batch_size: \"16\"\n",
      "2021-04-18 17:46:16,859  - patience: \"3\"\n",
      "2021-04-18 17:46:16,859  - anneal_factor: \"0.5\"\n",
      "2021-04-18 17:46:16,860  - max_epochs: \"10\"\n",
      "2021-04-18 17:46:16,861  - shuffle: \"True\"\n",
      "2021-04-18 17:46:16,861  - train_with_dev: \"False\"\n",
      "2021-04-18 17:46:16,862  - batch_growth_annealing: \"False\"\n",
      "2021-04-18 17:46:16,863 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,863 Model training base path: \"flairtransformers\"\n",
      "2021-04-18 17:46:16,864 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,864 Device: cuda\n",
      "2021-04-18 17:46:16,865 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:16,866 Embeddings storage mode: cpu\n",
      "2021-04-18 17:46:16,870 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:46:34,358 epoch 1 - iter 5/55 - loss 0.76445355 - samples/sec: 20.90 - lr: 0.000030\n",
      "2021-04-18 17:46:37,078 epoch 1 - iter 10/55 - loss 0.67372666 - samples/sec: 30.64 - lr: 0.000030\n",
      "2021-04-18 17:46:39,837 epoch 1 - iter 15/55 - loss 0.69250570 - samples/sec: 29.27 - lr: 0.000030\n",
      "2021-04-18 17:46:42,572 epoch 1 - iter 20/55 - loss 0.62868773 - samples/sec: 30.89 - lr: 0.000030\n",
      "2021-04-18 17:46:45,290 epoch 1 - iter 25/55 - loss 0.62115357 - samples/sec: 29.59 - lr: 0.000030\n",
      "2021-04-18 17:46:47,990 epoch 1 - iter 30/55 - loss 0.61240089 - samples/sec: 29.92 - lr: 0.000030\n",
      "2021-04-18 17:46:50,826 epoch 1 - iter 35/55 - loss 0.62419679 - samples/sec: 29.54 - lr: 0.000030\n",
      "2021-04-18 17:46:53,851 epoch 1 - iter 40/55 - loss 0.63856372 - samples/sec: 27.83 - lr: 0.000030\n",
      "2021-04-18 17:46:56,583 epoch 1 - iter 45/55 - loss 0.62688891 - samples/sec: 29.52 - lr: 0.000030\n",
      "2021-04-18 17:46:59,490 epoch 1 - iter 50/55 - loss 0.68164839 - samples/sec: 29.01 - lr: 0.000030\n",
      "2021-04-18 17:47:01,787 epoch 1 - iter 55/55 - loss 0.68447606 - samples/sec: 34.97 - lr: 0.000030\n",
      "2021-04-18 17:47:02,181 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:47:02,182 EPOCH 1 done: loss 0.6845 - lr 0.0000300\n",
      "2021-04-18 17:47:08,320 DEV : loss 0.6215452551841736 - score 0.6574\n",
      "2021-04-18 17:47:08,739 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 17:47:09,804 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:47:26,033 epoch 2 - iter 5/55 - loss 0.57608409 - samples/sec: 30.11 - lr: 0.000030\n",
      "2021-04-18 17:47:28,696 epoch 2 - iter 10/55 - loss 0.58983667 - samples/sec: 30.32 - lr: 0.000030\n",
      "2021-04-18 17:47:31,449 epoch 2 - iter 15/55 - loss 0.52843301 - samples/sec: 30.42 - lr: 0.000030\n",
      "2021-04-18 17:47:34,126 epoch 2 - iter 20/55 - loss 0.55529537 - samples/sec: 30.11 - lr: 0.000030\n",
      "2021-04-18 17:47:36,933 epoch 2 - iter 25/55 - loss 0.53161959 - samples/sec: 29.96 - lr: 0.000030\n",
      "2021-04-18 17:47:39,569 epoch 2 - iter 30/55 - loss 0.51344897 - samples/sec: 30.46 - lr: 0.000030\n",
      "2021-04-18 17:47:42,204 epoch 2 - iter 35/55 - loss 0.52198177 - samples/sec: 30.70 - lr: 0.000030\n",
      "2021-04-18 17:47:44,968 epoch 2 - iter 40/55 - loss 0.54874197 - samples/sec: 30.27 - lr: 0.000030\n",
      "2021-04-18 17:47:47,593 epoch 2 - iter 45/55 - loss 0.53749514 - samples/sec: 30.82 - lr: 0.000030\n",
      "2021-04-18 17:47:50,297 epoch 2 - iter 50/55 - loss 0.57312992 - samples/sec: 30.98 - lr: 0.000030\n",
      "2021-04-18 17:47:52,555 epoch 2 - iter 55/55 - loss 0.56248404 - samples/sec: 35.61 - lr: 0.000030\n",
      "2021-04-18 17:47:52,935 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:47:52,936 EPOCH 2 done: loss 0.5625 - lr 0.0000300\n",
      "2021-04-18 17:47:59,188 DEV : loss 0.6449724435806274 - score 0.7685\n",
      "2021-04-18 17:47:59,703 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-04-18 17:48:00,677 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:48:17,068 epoch 3 - iter 5/55 - loss 0.43152050 - samples/sec: 30.52 - lr: 0.000030\n",
      "2021-04-18 17:48:19,948 epoch 3 - iter 10/55 - loss 0.42078355 - samples/sec: 28.84 - lr: 0.000030\n",
      "2021-04-18 17:48:22,667 epoch 3 - iter 15/55 - loss 0.36350058 - samples/sec: 29.72 - lr: 0.000030\n",
      "2021-04-18 17:48:25,428 epoch 3 - iter 20/55 - loss 0.41612062 - samples/sec: 30.40 - lr: 0.000030\n",
      "2021-04-18 17:48:28,086 epoch 3 - iter 25/55 - loss 0.36799783 - samples/sec: 30.40 - lr: 0.000030\n",
      "2021-04-18 17:48:30,677 epoch 3 - iter 30/55 - loss 0.35278482 - samples/sec: 30.95 - lr: 0.000030\n",
      "2021-04-18 17:48:33,453 epoch 3 - iter 35/55 - loss 0.32848504 - samples/sec: 30.22 - lr: 0.000030\n",
      "2021-04-18 17:48:36,290 epoch 3 - iter 40/55 - loss 0.32444316 - samples/sec: 28.49 - lr: 0.000030\n",
      "2021-04-18 17:48:39,094 epoch 3 - iter 45/55 - loss 0.32015243 - samples/sec: 30.18 - lr: 0.000030\n",
      "2021-04-18 17:48:41,905 epoch 3 - iter 50/55 - loss 0.34905013 - samples/sec: 28.69 - lr: 0.000030\n",
      "2021-04-18 17:48:44,217 epoch 3 - iter 55/55 - loss 0.35096484 - samples/sec: 34.68 - lr: 0.000030\n",
      "2021-04-18 17:48:44,594 ----------------------------------------------------------------------------------------------------\n",
      "2021-04-18 17:48:44,595 EPOCH 3 done: loss 0.3510 - lr 0.0000300\n"
     ]
    }
   ],
   "source": [
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('./flair/transformers_low',\n",
    "              learning_rate=3e-5, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=10) # terminate after 5 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
